{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "#forkity fork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Classification\n",
    "\n",
    "For this assignment, you'll need to perform a classification on a dataset, as well as do some prep work on the data. \n",
    "\n",
    "The exact steps of what you need to do are flexible and up to you to some degree, however you should consider some of the important things we've mentioned recently, such as:\n",
    "<ul>\n",
    "<li> Is the target balanced?\n",
    "<li> Are there missing or erroneous values?\n",
    "<li> Are there categorical or numerical features?\n",
    "<li> Is there colinearity?\n",
    "<li> Are there outliers?\n",
    "<li> Should we normalize? \n",
    "<li> Do the distributions of the features give any indication that some may need work? \n",
    "</ul>\n",
    "\n",
    "Basically, the data is in the original, potentially dirty, format, and you need to find what should be cleaned, and do the cleaning. There is not one \"right\" answer to what has to be done, and you'll probably need to do it with at least something of an iterative process - find an issue, correct it, check the data, repeat.\n",
    "\n",
    "<b>The target that we are predicting is the loan_status. </b>\n",
    "\n",
    "## Grading\n",
    "\n",
    "The grades will be broken down as follows:\n",
    "<ul>\n",
    "<li> <b>30%</b> - a working predictive model with a reasonable level of accuracy. \n",
    "    <ul>\n",
    "    <li> For the accuracy part, it will not be explicitly graded, but compared to all the others. If you're in the same general range, that's good - if yours is drastically less accurate (or, I guess more accurate), then I'll adjust. There won't be a comparison of \"this person is 72.3% and this person is only 71.8% accurate, they fail.\"\n",
    "    <li> This data is larger than most of the small sample sets, so random variations due to train-test splits shouldn't be too bad. (If you're a keener you could loop)\n",
    "    <li> I will use the F1 score as the accuracy metric. \n",
    "    </ul>\n",
    "<li> <b>40%</b> - a clear and readable description of what steps you took to prepare the data, and a brief not on the rationale behind it. Did you do a log transformation to a skewed feature, did you remove outliers, did you remove a feature that has a lot of missing values? Please put this somewhere obvious and readable, consider the goal of the assignment to explain your process to me. \n",
    "    <ul>\n",
    "    <li> E.g. \"The target data was imbalanced, so I tried several resampling methods and chose the one with the highest accuracy of the resulting model\", \"the feature X had the same value for 95% of records, so I dropped it\". \n",
    "    <li> In this, please also state if you see a group that appears to be a good credit risk, and a group that is a bad credit risk, and indicate the evidence showing that. Please do this other than the most simplistic way - more money = better credit. If there are no such groups, state why you think this. This will likely be about 3 - 5 statements or points, you should provide evidence from the data, but it does not need to be an essay. (You may want to consider this question after you're pretty much done with the data prep and modelling.)\n",
    "    </ul>\n",
    "<li> <b>30%</b> - allowing your model to be \"deployed\". At the bottom of this file there is a small block of code to load in some test data (that I have), and calculate your accuracy. Your contribution to this part is to have a model that is ready to make predictions. Some specifics to consider:\n",
    "    <ul>\n",
    "    <li> The test data will be in exactly the same format as the dataset you're given. So any steps that you took to prepare your data for modelling will need to be mirroed here, so the new  data can be predicted. The easiest way to do this is to use a pipeline, but it is up to you. Remember the model only accepts data that is in a certain format - the one that you had the data in when it was trained, so when making predictions you need to make sure that is true. \n",
    "    <li> Since I'm providing test data, and your task is to just create a model, think about how that might impact your train-test splitting, both as you're developing and for the final product. \n",
    "    <li> Once the model is trained it should predict any data that is in the right format, so I should be able to provide any proper dataset, click run on that testing cell, and get predictions. I will not be doing anything that will purposefully make this harder or trickier, like including data that has errors or is in the wrong format, I just split the entire set of data, reserved part of it to test accuracy, and gave the rest to you. Things that you've changed (e.g. dropping a column, one-hot encoding) do need to be replicated at some point before the model can accept the new data to predict. In general we <b>do</b> want to check in our processing that our input is valid, this is kind of a junior introduction to that. \n",
    "    </ul>\n",
    "</ul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Credit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26967</td>\n",
       "      <td>27</td>\n",
       "      <td>120000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>B</td>\n",
       "      <td>14000</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8449</td>\n",
       "      <td>24</td>\n",
       "      <td>58000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>A</td>\n",
       "      <td>15700</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20983</td>\n",
       "      <td>30</td>\n",
       "      <td>45000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>11.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>5000</td>\n",
       "      <td>12.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>Y</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19612</td>\n",
       "      <td>35</td>\n",
       "      <td>35000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>5600</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30371</td>\n",
       "      <td>38</td>\n",
       "      <td>55000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>C</td>\n",
       "      <td>6500</td>\n",
       "      <td>11.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>Y</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  person_age  person_income person_home_ownership  \\\n",
       "0       26967          27         120000              MORTGAGE   \n",
       "1        8449          24          58000              MORTGAGE   \n",
       "2       20983          30          45000                  RENT   \n",
       "3       19612          35          35000              MORTGAGE   \n",
       "4       30371          38          55000                  RENT   \n",
       "\n",
       "   person_emp_length        loan_intent loan_grade  loan_amnt  loan_int_rate  \\\n",
       "0                3.0           PERSONAL          B      14000          11.99   \n",
       "1                8.0  DEBTCONSOLIDATION          A      15700           7.90   \n",
       "2               11.0            MEDICAL          C       5000          12.73   \n",
       "3                5.0          EDUCATION          B       5600          11.49   \n",
       "4                0.0          EDUCATION          C       6500          11.03   \n",
       "\n",
       "   loan_status  loan_percent_income cb_person_default_on_file  \\\n",
       "0            0                 0.12                         N   \n",
       "1            0                 0.27                         N   \n",
       "2            1                 0.11                         Y   \n",
       "3            0                 0.16                         N   \n",
       "4            0                 0.12                         Y   \n",
       "\n",
       "   cb_person_cred_hist_length  \n",
       "0                          10  \n",
       "1                           3  \n",
       "2                           8  \n",
       "3                           6  \n",
       "4                          12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Test\n",
    "\n",
    "Replace the green part with whatever you need to transform the fresh data into the format needed for your model to predict. \n",
    "\n",
    "<b>Note:</b> you could test and make sure that things are working OK here by taking part of your dataset, saving it in a separate CSV, and running it through here as a piece of test data. The accuracy results would be useless, but you'd confirm that the model works properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "######################\n",
    "# Insert whatever you need to do to prep the data here. \n",
    "# It might be nothing if you have a big pipeline. \n",
    "# Ensure that at the end your data is in two arrays - xtest and ytest\n",
    "# Ensure the name of your final model is \"model\"\n",
    "# Each should contain the ENTIRE x or y dataset in the test data. \n",
    "#\n",
    "# This part should be reusable - any dataset in this format should just run\n",
    "# and generate predictions and accuracy stats. \n",
    "# Please DO NOT do any train-test splitting here. \n",
    "#######################\n",
    "\n",
    "# This should work once you're done, as is. \n",
    "# uncomment the stuff below when ready to run.\n",
    "#print(\"F1:\",f1_score(ytest, prediction_labels))\n",
    "#conf_matrix = confusion_matrix(ytest, prediction_labels)\n",
    "#sns.heatmap(conf_matrix, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml3950')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
